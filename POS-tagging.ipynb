{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8tjOg0Gamy2",
        "outputId": "4cfc6460-54b3-49b0-c6fc-03afbf0b029c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--------------------------------------------------\n",
            "Testing First Order HMM\n",
            "--------------------------------------------------\n",
            "Most frequent tag (for unseen words): NN\n",
            "\n",
            "Unknown word performance:\n",
            "Total unknown words: 1698\n",
            "Unknown word accuracy: 0.2067\n",
            "\n",
            "First Order HMM - 36 tags:\n",
            "Overall accuracy: 0.8766\n",
            "Tag-wise accuracy: {'NNP': 0.7803242034656233, 'DT': 0.9891238670694864, 'NN': 0.9611046285492026, 'WP': 0.9811320754716981, 'VBZ': 0.884514435695538, 'NNS': 0.8404605263157895, 'VBD': 0.8412162162162162, 'RB': 0.7775590551181102, 'JJ': 0.739247311827957, 'IN': 0.9770171149144254, 'CD': 0.7414285714285714, 'PRP$': 1.0, 'VBP': 0.7741935483870968, 'VBN': 0.6930232558139535, 'JJS': 0.8636363636363636, 'WDT': 0.8111111111111111, 'RBS': 0.7, 'TO': 0.985781990521327, 'PRP': 0.9886039886039886, 'VBG': 0.6491803278688525, 'RP': 0.6904761904761905, 'CC': 0.9933035714285714, 'MD': 0.9073170731707317, 'VB': 0.8148148148148148, 'WRB': 0.9473684210526315, 'RBR': 0.38461538461538464, 'JJR': 0.875, ':': 1.0, 'EX': 0.9473684210526315, '-LRB-': 1.0, '-RRB-': 1.0, 'NNPS': 0.5535714285714286, 'PDT': 0.5, 'WP$': 1.0, 'SYM': 0.0, '#': 0.5, ',': 0.0, \"''\": 0.6666666666666666}\n",
            "Most frequent tag (for unseen words): O\n",
            "\n",
            "Unknown word performance:\n",
            "Total unknown words: 1698\n",
            "Unknown word accuracy: 0.1160\n",
            "\n",
            "First Order HMM - 4 tags:\n",
            "Overall accuracy: 0.8808\n",
            "Tag-wise accuracy: {'N': 0.8103693181818182, 'O': 0.997629582806574, 'V': 0.8188, 'A': 0.7747747747747747}\n",
            "\n",
            "--------------------------------------------------\n",
            "Testing Second Order HMM\n",
            "--------------------------------------------------\n",
            "Most frequent tag (for unseen words): NN\n",
            "\n",
            "Unknown word performance:\n",
            "Total unknown words: 1698\n",
            "Unknown word accuracy: 0.2126\n",
            "\n",
            "Second Order HMM - 36 tags:\n",
            "Overall accuracy: 0.8596\n",
            "Tag-wise accuracy: {'NNP': 0.7747344885410844, 'DT': 0.9812688821752266, 'NN': 0.9603267211201867, 'WP': 0.8301886792452831, 'VBZ': 0.8713910761154856, 'NNS': 0.8248355263157895, 'VBD': 0.8361486486486487, 'RB': 0.7303149606299213, 'JJ': 0.7267025089605734, 'IN': 0.9731051344743277, 'CD': 0.7157142857142857, 'PRP$': 0.9784172661870504, 'VBP': 0.7275985663082437, 'VBN': 0.672093023255814, 'JJS': 0.8181818181818182, 'WDT': 0.7222222222222222, 'RBS': 0.4, 'TO': 0.933649289099526, 'PRP': 0.9430199430199431, 'VBG': 0.6098360655737705, 'RP': 0.5238095238095238, 'CC': 0.9508928571428571, 'MD': 0.9170731707317074, 'VB': 0.8148148148148148, 'WRB': 0.8421052631578947, 'RBR': 0.34615384615384615, 'JJR': 0.7777777777777778, ':': 0.9152542372881356, 'EX': 0.6842105263157895, '-LRB-': 0.5416666666666666, '-RRB-': 0.875, 'NNPS': 0.48214285714285715, 'PDT': 0.25, 'WP$': 1.0, 'SYM': 0.0, '#': 1.0, ',': 0.0, \"''\": 0.6666666666666666}\n",
            "Most frequent tag (for unseen words): O\n",
            "\n",
            "Unknown word performance:\n",
            "Total unknown words: 1698\n",
            "Unknown word accuracy: 0.1160\n",
            "\n",
            "Second Order HMM - 4 tags:\n",
            "Overall accuracy: 0.8811\n",
            "Tag-wise accuracy: {'N': 0.8119673295454546, 'O': 0.9977876106194691, 'V': 0.8152, 'A': 0.7775900900900901}\n",
            "\n",
            "--------------------------------------------------\n",
            "Testing First Order HMM with word dependency\n",
            "--------------------------------------------------\n",
            "Most frequent tag (for unseen words): NN\n",
            "\n",
            "Unknown word performance:\n",
            "Total unknown words: 1698\n",
            "Unknown word accuracy: 0.2055\n",
            "\n",
            "First Order HMM with word dependency - 36 tags:\n",
            "Overall accuracy: 0.5395\n",
            "Tag-wise accuracy: {'NNP': 0.4991615427613192, 'DT': 0.8132930513595166, 'NN': 0.6787242318164138, 'WP': 0.22641509433962265, 'VBZ': 0.36220472440944884, 'NNS': 0.3050986842105263, 'VBD': 0.3125, 'RB': 0.24606299212598426, 'JJ': 0.4032258064516129, 'IN': 0.7990220048899755, 'CD': 0.29285714285714287, 'PRP$': 0.5539568345323741, 'VBP': 0.3118279569892473, 'VBN': 0.36511627906976746, 'JJS': 0.6136363636363636, 'WDT': 0.35555555555555557, 'RBS': 0.6, 'TO': 0.7322274881516587, 'PRP': 0.5413105413105413, 'VBG': 0.14426229508196722, 'RP': 0.14285714285714285, 'CC': 0.4174107142857143, 'MD': 0.48292682926829267, 'VB': 0.6764132553606238, 'WRB': 0.34210526315789475, 'RBR': 0.23076923076923078, 'JJR': 0.3055555555555556, ':': 0.13559322033898305, 'EX': 0.5263157894736842, '-LRB-': 0.2916666666666667, '-RRB-': 0.2916666666666667, 'NNPS': 0.25, 'PDT': 0.0, 'WP$': 0.0, 'SYM': 0.0, '#': 0.5, ',': 0.0, \"''\": 0.0}\n",
            "Most frequent tag (for unseen words): O\n",
            "\n",
            "Unknown word performance:\n",
            "Total unknown words: 1698\n",
            "Unknown word accuracy: 0.1160\n",
            "\n",
            "First Order HMM with word dependency - 4 tags:\n",
            "Overall accuracy: 0.5915\n",
            "Tag-wise accuracy: {'N': 0.677734375, 'O': 0.693109987357775, 'V': 0.3376, 'A': 0.3130630630630631}\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from collections import defaultdict, Counter\n",
        "from typing import List, Dict, Tuple, Set\n",
        "import re\n",
        "\n",
        "class HMMTagger:\n",
        "    def __init__(self, order: int = 1, word_depends_prev: bool = False):\n",
        "        self.order = order\n",
        "        self.word_depends_prev = word_depends_prev\n",
        "\n",
        "        # Simplified data structures using nested defaultdict\n",
        "        if word_depends_prev:\n",
        "            self.emission_counts = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))\n",
        "        else:\n",
        "            self.emission_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        self.transition_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        if order == 2:\n",
        "            self.second_order_counts = defaultdict(lambda: defaultdict(int))\n",
        "\n",
        "        self.tag_counts = defaultdict(int)\n",
        "        self.vocabulary = set()\n",
        "        self.most_frequent_tag = None\n",
        "\n",
        "    def train(self, sentences: List[List[Tuple[str, str]]]):\n",
        "        \"\"\"Two-pass training approach for better statistics.\"\"\"\n",
        "        # First pass: collect word and tag statistics\n",
        "        for sentence in sentences:\n",
        "            for word, tag in sentence:\n",
        "                self.vocabulary.add(word)\n",
        "                self.tag_counts[tag] += 1\n",
        "\n",
        "        # Set most frequent tag for unseen words\n",
        "        self.most_frequent_tag = max(self.tag_counts.items(), key=lambda x: x[1])[0]\n",
        "        print(f\"Most frequent tag (for unseen words): {self.most_frequent_tag}\")\n",
        "\n",
        "        # Second pass: collect transition and emission statistics\n",
        "        for sentence in sentences:\n",
        "            previous_tag = '<START>'\n",
        "            previous_tag2 = '<START>' if self.order == 2 else None\n",
        "            previous_word = '<START>' if self.word_depends_prev else None\n",
        "\n",
        "            for word, tag in sentence:\n",
        "                # Update emission counts\n",
        "                if self.word_depends_prev:\n",
        "                    self.emission_counts[tag][previous_word][word] += 1\n",
        "                else:\n",
        "                    self.emission_counts[tag][word] += 1\n",
        "\n",
        "                # Update transition counts\n",
        "                self.transition_counts[previous_tag][tag] += 1\n",
        "                if self.order == 2:\n",
        "                    self.second_order_counts[(previous_tag2, previous_tag)][tag] += 1\n",
        "\n",
        "                # Update previous states\n",
        "                previous_word = word if self.word_depends_prev else None\n",
        "                previous_tag2 = previous_tag if self.order == 2 else None\n",
        "                previous_tag = tag\n",
        "\n",
        "        self._normalize_probabilities()\n",
        "\n",
        "    def _normalize_probabilities(self):\n",
        "        \"\"\"Normalize counts to probabilities with simple smoothing.\"\"\"\n",
        "        # Normalize transition probabilities\n",
        "        for prev_tag in self.transition_counts:\n",
        "            total = sum(self.transition_counts[prev_tag].values())\n",
        "            if total > 0:\n",
        "                for tag in self.transition_counts[prev_tag]:\n",
        "                    self.transition_counts[prev_tag][tag] /= total\n",
        "\n",
        "        # Normalize second-order transitions if applicable\n",
        "        if self.order == 2:\n",
        "            for prev_tags in self.second_order_counts:\n",
        "                total = sum(self.second_order_counts[prev_tags].values())\n",
        "                if total > 0:\n",
        "                    for tag in self.second_order_counts[prev_tags]:\n",
        "                        self.second_order_counts[prev_tags][tag] /= total\n",
        "\n",
        "        # Normalize emission probabilities\n",
        "        if self.word_depends_prev:\n",
        "            for tag in self.emission_counts:\n",
        "                for prev_word in self.emission_counts[tag]:\n",
        "                    total = sum(self.emission_counts[tag][prev_word].values())\n",
        "                    if total > 0:\n",
        "                        for word in self.emission_counts[tag][prev_word]:\n",
        "                            self.emission_counts[tag][prev_word][word] /= total\n",
        "        else:\n",
        "            for tag in self.emission_counts:\n",
        "                total = sum(self.emission_counts[tag].values())\n",
        "                if total > 0:\n",
        "                    for word in self.emission_counts[tag]:\n",
        "                        self.emission_counts[tag][word] /= total\n",
        "\n",
        "    def get_emission_probability(self, tag: str, word: str, prev_word: str = None) -> float:\n",
        "        \"\"\"Simplified emission probability calculation with basic smoothing.\"\"\"\n",
        "        if self.word_depends_prev:\n",
        "            if word not in self.vocabulary:\n",
        "                return 1.0 if tag == self.most_frequent_tag else 1e-10\n",
        "            return self.emission_counts[tag][prev_word].get(word, 1e-10)\n",
        "        else:\n",
        "            if word not in self.vocabulary:\n",
        "                return 1.0 if tag == self.most_frequent_tag else 1e-10\n",
        "            return self.emission_counts[tag].get(word, 1e-10)\n",
        "\n",
        "    def viterbi(self, sentence: List[str]) -> List[str]:\n",
        "        \"\"\"Simplified Viterbi implementation without log probabilities.\"\"\"\n",
        "        n = len(sentence)\n",
        "        tags = list(self.tag_counts.keys())\n",
        "\n",
        "        viterbi = defaultdict(lambda: defaultdict(float))\n",
        "        backpointer = defaultdict(lambda: defaultdict(str))\n",
        "\n",
        "        # Initialize for first word\n",
        "        prev_word = '<START>'\n",
        "        for tag in tags:\n",
        "            emission_prob = self.get_emission_probability(tag, sentence[0], prev_word)\n",
        "            viterbi[tag][0] = self.transition_counts['<START>'].get(tag, 1e-10) * emission_prob\n",
        "\n",
        "        # Process rest of sentence\n",
        "        for i in range(1, n):\n",
        "            prev_word = sentence[i-1] if self.word_depends_prev else None\n",
        "            for tag in tags:\n",
        "                emission_prob = self.get_emission_probability(tag, sentence[i], prev_word)\n",
        "\n",
        "                if self.order == 1:\n",
        "                    max_prob, best_prev_tag = max(\n",
        "                        (viterbi[prev_tag][i-1] *\n",
        "                         self.transition_counts[prev_tag].get(tag, 1e-10) *\n",
        "                         emission_prob, prev_tag)\n",
        "                        for prev_tag in tags\n",
        "                    )\n",
        "                else:\n",
        "                    if i == 1:\n",
        "                        max_prob, best_prev_tag = max(\n",
        "                            (viterbi[prev_tag][i-1] *\n",
        "                             self.transition_counts[prev_tag].get(tag, 1e-10) *\n",
        "                             emission_prob, prev_tag)\n",
        "                            for prev_tag in tags\n",
        "                        )\n",
        "                    else:\n",
        "                        max_prob, best_prev_tag = max(\n",
        "                            (viterbi[prev_tag][i-1] *\n",
        "                             self.second_order_counts.get((backpointer[prev_tag][i-1], prev_tag), {}).get(tag, 1e-10) *\n",
        "                             emission_prob, prev_tag)\n",
        "                            for prev_tag in tags\n",
        "                        )\n",
        "\n",
        "                viterbi[tag][i] = max_prob\n",
        "                backpointer[tag][i] = best_prev_tag\n",
        "\n",
        "        # Backtrack to find best sequence\n",
        "        best_last_tag = max(tags, key=lambda tag: viterbi[tag][n-1])\n",
        "        best_sequence = [best_last_tag]\n",
        "        for i in range(n-1, 0, -1):\n",
        "            best_sequence.insert(0, backpointer[best_sequence[0]][i])\n",
        "\n",
        "        return best_sequence\n",
        "\n",
        "    def tag_sentence(self, sentence: List[str]) -> List[str]:\n",
        "        \"\"\"Tag a sentence.\"\"\"\n",
        "        if not sentence:\n",
        "            return []\n",
        "        return self.viterbi(sentence)\n",
        "\n",
        "def load_and_split_data(json_data: List[List], train_ratio: float = 0.8) -> Tuple[List[List[Tuple[str, str]]], List[List[Tuple[str, str]]]]:\n",
        "    \"\"\"Simplified data loading and preprocessing.\"\"\"\n",
        "    processed_data = []\n",
        "\n",
        "    for sentence_data in json_data:\n",
        "        # Simple cleaning\n",
        "        text = sentence_data[0]\n",
        "        tags = sentence_data[1]\n",
        "\n",
        "        # Basic cleaning\n",
        "        text = re.sub(r',', '', text)\n",
        "        text = re.sub(r'\\.(?=[^\\.]*$)', '', text)\n",
        "        words = text.split()\n",
        "\n",
        "        # Create word-tag pairs\n",
        "        if len(words) == len(tags):\n",
        "            sentence_pairs = list(zip(words, tags))\n",
        "            processed_data.append(sentence_pairs)\n",
        "\n",
        "    # Simple random split\n",
        "    np.random.seed(42)\n",
        "    split_idx = int(len(processed_data) * train_ratio)\n",
        "    indices = list(range(len(processed_data)))\n",
        "    np.random.shuffle(indices)\n",
        "\n",
        "    train_data = [processed_data[i] for i in indices[:split_idx]]\n",
        "    test_data = [processed_data[i] for i in indices[split_idx:]]\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "def evaluate_tagger(tagger: HMMTagger, test_data: List[List[Tuple[str, str]]]) -> Tuple[float, Dict[str, float]]:\n",
        "    \"\"\"Evaluate tagger performance.\"\"\"\n",
        "    total_correct = 0\n",
        "    total_words = 0\n",
        "    unseen_words_correct = 0\n",
        "    unseen_words_total = 0\n",
        "    tag_correct = defaultdict(int)\n",
        "    tag_total = defaultdict(int)\n",
        "\n",
        "    for sentence in test_data:\n",
        "        words = [word for word, tag in sentence]\n",
        "        true_tags = [tag for word, tag in sentence]\n",
        "        pred_tags = tagger.tag_sentence(words)\n",
        "\n",
        "        for word, true_tag, pred_tag in zip(words, true_tags, pred_tags):\n",
        "            if true_tag == pred_tag:\n",
        "                total_correct += 1\n",
        "                tag_correct[true_tag] += 1\n",
        "            total_words += 1\n",
        "            tag_total[true_tag] += 1\n",
        "\n",
        "            if word not in tagger.vocabulary:\n",
        "                unseen_words_total += 1\n",
        "                if true_tag == pred_tag:\n",
        "                    unseen_words_correct += 1\n",
        "\n",
        "    # Calculate accuracies\n",
        "    overall_accuracy = total_correct / total_words if total_words > 0 else 0\n",
        "    tag_accuracy = {\n",
        "        tag: tag_correct[tag] / tag_total[tag]\n",
        "        for tag in tag_total if tag_total[tag] > 0\n",
        "    }\n",
        "\n",
        "    # Print unseen word performance\n",
        "    if unseen_words_total > 0:\n",
        "        unseen_accuracy = unseen_words_correct / unseen_words_total\n",
        "        print(f\"\\nUnknown word performance:\")\n",
        "        print(f\"Total unknown words: {unseen_words_total}\")\n",
        "        print(f\"Unknown word accuracy: {unseen_accuracy:.4f}\")\n",
        "\n",
        "    return overall_accuracy, tag_accuracy\n",
        "\n",
        "def collapse_tags(tag: str) -> str:\n",
        "    \"\"\"Collapse tags into 4 categories.\"\"\"\n",
        "    if tag in {'NN', 'NNS', 'NNP', 'NNPS'}:\n",
        "        return 'N'\n",
        "    elif tag in {'VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'}:\n",
        "        return 'V'\n",
        "    elif tag in {'JJ', 'JJR', 'JJS', 'RB', 'RBR', 'RBS'}:\n",
        "        return 'A'\n",
        "    else:\n",
        "        return 'O'\n",
        "\n",
        "def convert_to_collapsed_tags(data: List[List[Tuple[str, str]]]) -> List[List[Tuple[str, str]]]:\n",
        "    \"\"\"Convert dataset to use collapsed tag set.\"\"\"\n",
        "    return [[(word, collapse_tags(tag)) for word, tag in sentence] for sentence in data]\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the HMM POS tagger.\"\"\"\n",
        "    try:\n",
        "        # Load data\n",
        "        with open('/content/penn-data.json', 'r') as f:\n",
        "            json_data = json.load(f)\n",
        "\n",
        "        # Split data\n",
        "        train_data, test_data = load_and_split_data(json_data)\n",
        "\n",
        "        # Test configurations\n",
        "        configs = [\n",
        "            (1, False, \"First Order HMM\"),\n",
        "            (2, False, \"Second Order HMM\"),\n",
        "            (1, True, \"First Order HMM with word dependency\")\n",
        "        ]\n",
        "\n",
        "        for order, word_depends_prev, name in configs:\n",
        "            print(f\"\\n{'-'*50}\")\n",
        "            print(f\"Testing {name}\")\n",
        "            print(f\"{'-'*50}\")\n",
        "\n",
        "            # 36-tag version\n",
        "            tagger = HMMTagger(order=order, word_depends_prev=word_depends_prev)\n",
        "            tagger.train(train_data)\n",
        "            accuracy, tag_accuracy = evaluate_tagger(tagger, test_data)\n",
        "            print(f\"\\n{name} - 36 tags:\")\n",
        "            print(f\"Overall accuracy: {accuracy:.4f}\")\n",
        "            print(\"Tag-wise accuracy:\", tag_accuracy)\n",
        "\n",
        "            # 4-tag version\n",
        "            collapsed_train = convert_to_collapsed_tags(train_data)\n",
        "            collapsed_test = convert_to_collapsed_tags(test_data)\n",
        "            collapsed_tagger = HMMTagger(order=order, word_depends_prev=word_depends_prev)\n",
        "            collapsed_tagger.train(collapsed_train)\n",
        "            collapsed_accuracy, collapsed_tag_accuracy = evaluate_tagger(\n",
        "                collapsed_tagger,\n",
        "                collapsed_test\n",
        "            )\n",
        "            print(f\"\\n{name} - 4 tags:\")\n",
        "            print(f\"Overall accuracy: {collapsed_accuracy:.4f}\")\n",
        "            print(\"Tag-wise accuracy:\", collapsed_tag_accuracy)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}